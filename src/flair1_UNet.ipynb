{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA2ZRC0bFMHw"
      },
      "source": [
        "# Sementic segmentation of flair1 data with a basic UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1awXQhk2K4",
        "outputId": "95f8b7d9-a58f-47a2-d4ac-4557671bc296"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/BertilleT/LandCover_map_Transformers_SSL.git\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak99YeIZFMH1"
      },
      "outputs": [],
      "source": [
        "# import all the necessary modules\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "from utils import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PvI9RLcFMH3"
      },
      "outputs": [],
      "source": [
        "dict_classes = {\n",
        "1   : 'building',\n",
        "2   : 'pervious surface',\n",
        "3   : 'impervious surface',\n",
        "4   : 'bare soil',\n",
        "5   : 'water',\n",
        "6   : 'coniferous',\n",
        "7   : 'deciduous',\n",
        "8   : 'brushwood',\n",
        "9   : 'vineyard',\n",
        "10  : 'herbaceous vegetation',\n",
        "11  : 'agricultural land',\n",
        "12  : 'plowed land',\n",
        "13  : 'swimming_pool',\n",
        "14  : 'snow',\n",
        "15  : 'clear cut',\n",
        "16  : 'mixed',\n",
        "17  : 'ligneous',\n",
        "18  : 'greenhouse',\n",
        "19  : 'other'}\n",
        "\n",
        "colors = {\n",
        "1   : '#db0e9a',\n",
        "2   : '#938e7b',\n",
        "3   : '#f80c00',\n",
        "4   : '#a97101',\n",
        "5   : '#1553ae',\n",
        "6   : '#194a26',\n",
        "7   : '#46e483',\n",
        "8   : '#f3a60d',\n",
        "9   : '#660082',\n",
        "10  : '#55ff00',\n",
        "11  : '#fff30d',\n",
        "12  : '#e4df7c',\n",
        "13  : '#3de6eb',\n",
        "14  : '#ffffff',\n",
        "15  : '#8ab3a0',\n",
        "16  : '#6b714f',\n",
        "17  : '#c5dc42',\n",
        "18  : '#9999ff',\n",
        "19  : '#000000'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBfbdXpfFMH4"
      },
      "source": [
        "## Prepare the data\n",
        "1) Download the data and split it into training, validation and test sets.\n",
        "2) Analyse the balance of classes in the dataset.\n",
        "3) Create a Dataloader\n",
        "4) Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRTzaRLjFMH5"
      },
      "outputs": [],
      "source": [
        "class Flair1Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder_path, seed = 42):\n",
        "        super(Flair1Dataset, self).__init__()\n",
        "        self.resize_transform = transforms.Resize((256, 256))\n",
        "        self.resize_transform_l = transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        self.folder_path = folder_path\n",
        "        self.img_files = sorted(list(get_data_paths(Path(self.folder_path), 'image*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
        "        self.mask_files = sorted(list(get_data_paths(Path(self.folder_path), 'mask*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
        "        self.total = len(self.img_files)\n",
        "        self.n_classes = len(dict_classes)\n",
        "        self.n_inputs = 3\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_files[idx]\n",
        "        mask_path = self.mask_files[idx]\n",
        "\n",
        "        data = rasterio.open(img_path).read()\n",
        "        data = data[0:3, :, :]\n",
        "        label = rasterio.open(mask_path).read()\n",
        "        label = label - 1\n",
        "        # Convert data to PIL Image for resizing\n",
        "        data = np.transpose(data, (1, 2, 0))\n",
        "        data = transforms.ToPILImage()(data)\n",
        "        data = self.resize_transform(data)\n",
        "        # Convert back to tensor\n",
        "        data = transforms.ToTensor()(data)\n",
        "\n",
        "        # Convert label to PIL Image for resizing\n",
        "        label = np.transpose(label, (1, 2, 0))\n",
        "        label = transforms.ToPILImage()(label)\n",
        "        label = self.resize_transform_l(label)\n",
        "        #print values uniques in label\n",
        "        # Convert back to tensor\n",
        "        label = torch.from_numpy(np.array(label, dtype=np.uint8))\n",
        "        label = label.long()\n",
        "\n",
        "        #Turn data and label into float between 0 and 1\n",
        "        # data = data / 255\n",
        "        # label = label / 255\n",
        "        return data, label\n",
        "\n",
        "    def get_per_per_class(self):\n",
        "        class_per = dict.fromkeys(range(1,20), 0)\n",
        "        total_pixels = 0\n",
        "        for i in range(len(self)):\n",
        "            _, label = self[i]\n",
        "            for j in range(1,20):\n",
        "                class_per[j] += torch.sum(label == j).item()\n",
        "            total_pixels += label.numel()\n",
        "        for j in range(1,20):\n",
        "            class_per[j] = class_per[j] / total_pixels\n",
        "        return class_per\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQlIJRoPFMH5"
      },
      "outputs": [],
      "source": [
        "#folder_path = 'LandCover_map_Transformers_SSL/data/flair1_subset/'\n",
        "train_path = 'LandCover_map_Transformers_SSL/data/flair1_subset/train_500'\n",
        "val_path = 'LandCover_map_Transformers_SSL/data/flair1_subset/val_100'\n",
        "test_path = 'LandCover_map_Transformers_SSL/data/flair1_subset/test_100'\n",
        "batch_size = 32\n",
        "use_gpu = True\n",
        "max_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "xvBPlBl-FMH6",
        "outputId": "f4389e9a-062c-475f-bc47-d9fa128988ef"
      },
      "outputs": [],
      "source": [
        "toy_ds = Flair1Dataset(train_path)\n",
        "toy_dl = torch.utils.data.DataLoader(toy_ds, batch_size=batch_size, shuffle=True)\n",
        "img, msk = next(iter(toy_dl))\n",
        "plot_image_mask(img[0], msk[0], colors, dict_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE8B-qmDFMH7"
      },
      "outputs": [],
      "source": [
        "train_ds = Flair1Dataset(train_path)\n",
        "val_ds = Flair1Dataset(val_path)\n",
        "test_ds = Flair1Dataset(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPBXlOnUFMH8"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNHjEHdFMH8"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQzUWz-6FMH9"
      },
      "outputs": [],
      "source": [
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2), DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(\n",
        "                in_channels, in_channels // 2, kernel_size=2, stride=2\n",
        "            )\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD_ybmnxFMH-"
      },
      "source": [
        "### Define metric: pixel-wise accuracy and MIoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crX5-759FMH_"
      },
      "outputs": [],
      "source": [
        "class ConfMatrix():\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "        self.state = np.zeros((self.num_classes, self.num_classes))\n",
        "\n",
        "    def calc(self, gt, pred):\n",
        "        \"\"\" calcs and returns the CM without saveing it to state \"\"\"\n",
        "        return confusion_matrix(gt.flatten(),\n",
        "                                pred.flatten(),\n",
        "                                labels=np.arange(self.num_classes))\n",
        "\n",
        "    def get_existing_classes(self):\n",
        "        return sum(np.sum(self.state, axis=1) > 0)\n",
        "\n",
        "    def add(self, gt, pred):\n",
        "        \"\"\" adds one label mask to the confusion matrix \"\"\"\n",
        "\n",
        "        assert gt.shape == pred.shape\n",
        "        assert gt.shape == (256, 256)\n",
        "\n",
        "        gt = gt.flatten()\n",
        "        pred = pred.flatten()\n",
        "        pred = pred[gt != 255]\n",
        "        gt = gt[gt != 255]\n",
        "\n",
        "        if not gt.size == 0:\n",
        "            self.state += confusion_matrix(gt, pred,\n",
        "                                           labels=np.arange(self.num_classes))\n",
        "\n",
        "        return None\n",
        "\n",
        "    def add_batch(self, gt, pred):\n",
        "        \"\"\" adds a batch of label masks to the confusion matrix \"\"\"\n",
        "\n",
        "        # convert pytorch tensors to numpy arrays\n",
        "        if not isinstance(gt, np.ndarray):\n",
        "            gt = gt.cpu().numpy()\n",
        "            pred = pred.cpu().numpy()\n",
        "\n",
        "        assert len(gt.shape) == 3       # assert C x W x H\n",
        "\n",
        "        noc = gt.shape[0]               # number of channels\n",
        "        for batchindex in range(noc):   # iterate over batch\n",
        "            self.add(gt[batchindex], pred[batchindex])\n",
        "\n",
        "        return None\n",
        "\n",
        "    def norm_on_lines(self):\n",
        "        \"\"\" norms along the lines of the matrix \"\"\"\n",
        "\n",
        "        a = self.state\n",
        "        b = np.sum(self.state, axis=1)[:, None]\n",
        "        return np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
        "\n",
        "    def get_aa(self):\n",
        "        confmatrix = self.norm_on_lines()\n",
        "        return np.diagonal(confmatrix).sum() / self.get_existing_classes()\n",
        "\n",
        "    def get_IoU(self):\n",
        "        res = np.zeros(self.num_classes)\n",
        "        for i in range(self.num_classes):\n",
        "            cm = self.state\n",
        "            a = cm[i, i]\n",
        "            b = (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
        "            res[i] = np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
        "        return res\n",
        "\n",
        "    def get_mIoU(self):\n",
        "        return np.mean(self.get_IoU())\n",
        "\n",
        "\n",
        "def AA(gt, pred, num_classes):\n",
        "    \"\"\" This is the mean over the diagonal of the confusion\n",
        "    matrix when it's normed \"\"\"\n",
        "\n",
        "    cm = ConfMatrix(num_classes)\n",
        "    cm.add(gt, pred)\n",
        "    confmatrix = cm.norm_on_lines()\n",
        "\n",
        "    return np.mean(np.diagonal(confmatrix))\n",
        "\n",
        "\n",
        "def IoU(gt, pred, num_classes):\n",
        "    \"\"\"\n",
        "    the intersection over union for class i can be calculated as follows:\n",
        "\n",
        "\n",
        "    get the intersection:\n",
        "        >>> thats the element [i,i] of the confusion matrix (cm)\n",
        "\n",
        "    the union:\n",
        "        >>> is the sum over row with index i plus the sum over line with index\n",
        "        i minux the diagonal element [i,i] (otherwise its counted twice)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    cm = ConfMatrix(num_classes).calc(gt, pred)\n",
        "\n",
        "    res = np.zeros(num_classes)\n",
        "    for i in range(num_classes):\n",
        "        res[i] = cm[i, i] / (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def mIoU(gt, pred, num_classes):\n",
        "    return np.mean(IoU(gt, pred, num_classes))\n",
        "\n",
        "class PixelwiseMetrics(object):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Initialize dictionaries to store class-wise statistics\n",
        "        self.data = {\"pixelclass_\" + str(i): {\"correct\": 0, \"total\": 0} for i in range(num_classes)}\n",
        "\n",
        "    def add_batch(self, y, y_hat):\n",
        "        for c in range(self.num_classes):\n",
        "            class_data = self.data[\"pixelclass_\" + str(c)]\n",
        "            preds_c = y_hat == c\n",
        "            targs_c = y == c\n",
        "            num_correct = (preds_c * targs_c).sum().cpu().detach().numpy()\n",
        "            num_pixels = np.sum(targs_c.cpu().detach().numpy())\n",
        "\n",
        "            # Update class-wise statistics\n",
        "            class_data[\"correct\"] += num_correct\n",
        "            class_data[\"total\"] += num_pixels\n",
        "\n",
        "    def get_classwise_accuracy(self):\n",
        "        cw_acc_ = {k: el['correct'] / el['total'] if el['total'] > 0 else 0.0 for k, el in self.data.items()}\n",
        "        return cw_acc_\n",
        "\n",
        "    def get_average_accuracy(self):\n",
        "        cw_acc = self.get_classwise_accuracy()\n",
        "        return np.mean(list(cw_acc.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v16jTJoDFMIA"
      },
      "source": [
        "## Create the functions for training, validation and test, with plots of the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmCwCySEFMIA"
      },
      "outputs": [],
      "source": [
        "# main training function (trains for one epoch)\n",
        "def train(model, train_loader, loss_fn, optimizer):\n",
        "\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # main training loop\n",
        "    pbar = tqdm(total=len(train_loader), desc=\"[Train]\")\n",
        "    training_loss = 0\n",
        "    pixel_acc = PixelwiseMetrics(train_loader.dataset.n_classes)\n",
        "    conf_mat = ConfMatrix(train_loader.dataset.n_classes)\n",
        "    for batch_idx, (image, target) in enumerate(train_loader):\n",
        "        #print(image.shape)\n",
        "        # reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # move data to gpu if model is on gpu\n",
        "        if use_gpu:\n",
        "            image, target = image.cuda(), target.cuda()\n",
        "\n",
        "        # forward pass\n",
        "        prediction = model(image)\n",
        "        #print(target.shape)\n",
        "        training_loss += loss_fn(prediction, target).data.item()\n",
        "        loss = loss_fn(prediction, target)\n",
        "        pixel_acc.add_batch(target, prediction.max(1)[1])\n",
        "        conf_mat.add_batch(target, prediction.max(1)[1])\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update progressbar\n",
        "\n",
        "        '''    pbar.set_description(\"[Train] Loss: {:.4f}\".format(\n",
        "                                round(training_loss.item(), 4)))\n",
        "        pbar.set_description(\"[Train] Pixel-wise accuracy: {:.2f}%\".format(\n",
        "                                round(pixel_acc.get_average_accuracy() * 100, 2)))\n",
        "        pbar.set_description(\"[Train] mIoU: {:.2f}%\".format(\n",
        "                                round(conf_mat.get_mIoU()) * 100, 2))'''\n",
        "        pbar.update()\n",
        "\n",
        "    # close progressbar and flush to disk\n",
        "    pbar.close()\n",
        "    training_loss /= len(train_loader)\n",
        "    return model, training_loss, pixel_acc.get_average_accuracy(), pixel_acc.get_classwise_accuracy(), conf_mat.get_mIoU()\n",
        "\n",
        "# main validation function (validates current model)\n",
        "def val(model, val_loader, loss_fn, optimizer):\n",
        "\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # main validation loop\n",
        "    pbar = tqdm(total=len(val_loader), desc=\"[Val]\")\n",
        "    loss = 0\n",
        "    val_pixel_acc = PixelwiseMetrics(val_loader.dataset.n_classes)\n",
        "    val_conf_mat = ConfMatrix(val_loader.dataset.n_classes)\n",
        "\n",
        "    for batch_idx, (image, target) in enumerate(val_loader):\n",
        "\n",
        "        # move data to gpu if model is on gpu\n",
        "        if use_gpu:\n",
        "            image, target = image.cuda(), target.cuda()\n",
        "\n",
        "        # forward pass\n",
        "        with torch.no_grad():\n",
        "            prediction = model(image)\n",
        "        loss += loss_fn(prediction, target).cpu().item()\n",
        "\n",
        "        # calculate error metrics\n",
        "        val_conf_mat.add_batch(target, prediction.max(1)[1])\n",
        "        val_pixel_acc.add_batch(target, prediction.max(1)[1])\n",
        "\n",
        "        # update progressbar\n",
        "        pbar.update()\n",
        "\n",
        "    '''    # close progressbar\n",
        "    pbar.set_description(\"[Val] Pixel-wise accuracy: {:.2f}%\".format(\n",
        "                            round(val_pixel_acc.get_average_accuracy() * 100, 2)))'''\n",
        "    pbar.close()\n",
        "\n",
        "    model.train()\n",
        "    return loss / len(val_loader), val_pixel_acc.get_average_accuracy(), val_pixel_acc.get_classwise_accuracy(), val_conf_mat.get_mIoU()\n",
        "\n",
        "def export_model(model, optimizer=None, name=None, step=None):\n",
        "\n",
        "    # set output filename\n",
        "    if name is not None:\n",
        "        out_file = name\n",
        "    else:\n",
        "        out_file = \"checkpoint\"\n",
        "        if step is not None:\n",
        "            out_file += \"_step_\" + str(step)\n",
        "    #out_file = os.path.join(self.args.checkpoint_dir, out_file + \".pth\")\n",
        "\n",
        "    # save model\n",
        "    data = {\"model_state_dict\": model.state_dict()}\n",
        "    if step is not None:\n",
        "        data[\"step\"] = step\n",
        "    if optimizer is not None:\n",
        "\n",
        "        data[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
        "    torch.save(data, out_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4QnchibFMIB"
      },
      "source": [
        "## Run the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UujS7oq0FMIB",
        "outputId": "5c57a498-cc2f-4088-f734-78bc50774fcb"
      },
      "outputs": [],
      "source": [
        "n_classes = train_ds.n_classes\n",
        "n_inputs = train_ds.n_inputs\n",
        "model = UNet(n_classes=n_classes, n_channels=n_inputs) #pixel value from 1 to 18\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu') # Move model to GPU if available\n",
        "train_pixelAcc = PixelwiseMetrics(n_classes)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=255, reduction='mean')\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    # run training for one epoch\n",
        "    model, tr_loss, tr_mean_acc, tr_class_acc, mIoU = train(model, train_dl, loss_fn, optimizer)\n",
        "    train_losses.append(tr_loss)\n",
        "    # run validation\n",
        "    val_loss, val_mean_acc, val_class_acc, mIoU = val(model, val_dl, loss_fn, optimizer)\n",
        "    val_losses.append(val_loss)\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"Training loss: \", tr_loss)\n",
        "    print(\"Training mean accuracy: \", tr_mean_acc)\n",
        "    print(\"Training classwise accuracy: \", tr_class_acc)\n",
        "    print(\"Training mIoU: \", mIoU)\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Validation loss: \", val_loss)\n",
        "    print(\"Validation mean accuracy: \", val_mean_acc)\n",
        "    print(\"Validation classwise accuracy: \", val_class_acc)\n",
        "    print(\"Validation mIoU: \", mIoU)\n",
        "    #trainer.export_model(model, args.checkpoint_dir, name=\"final\")\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2DMTvg4FMIB",
        "outputId": "a29b72c7-ac99-444a-989b-4adf41033b14"
      },
      "outputs": [],
      "source": [
        "# Run validation with the trained model on vl_dl\n",
        "val_loss, val_mean_acc, val_class_acc, mIoU = val(model, val_dl, loss_fn, optimizer)\n",
        "print(\"-----------------------\")\n",
        "print(\"Validation loss: \", val_loss)\n",
        "print(\"Validation mean accuracy: \", val_mean_acc)\n",
        "print(\"Validation classwise accuracy: \", val_class_acc)\n",
        "print(\"Validation mIoU: \", mIoU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnJNVXdUFMIB",
        "outputId": "e58e1ed4-0124-4df8-cbe3-0bb7cbcd9e96"
      },
      "outputs": [],
      "source": [
        "# print validation accuracy class by class\n",
        "for i in range(len(val_class_acc)):\n",
        "    print(i+1, dict_classes[i+1], \" : \", val_class_acc[\"pixelclass_\"+str(i)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "VWrNa_k1FMIB",
        "outputId": "91e0c3b8-0364-4bcf-c78f-0049c4ed7ad5"
      },
      "outputs": [],
      "source": [
        "# call get_per_per_class() to get the percentage of each class in the dataset\n",
        "per_class = train_ds.get_per_per_class()\n",
        "plot_per_classes(per_class, dict_classes, colors, title = 'toy training dataset')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
