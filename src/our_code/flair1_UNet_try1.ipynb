{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sementic segmentation of flair1 data with a basic UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "from metric import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "1) Download the data and split it into training, validation and test sets. \n",
    "2) Analyse the balance of classes in the dataset. \n",
    "3) Create a Dataloader\n",
    "4) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../../data/flair1/'\n",
    "batch_size = 32\n",
    "use_gpu = True\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_ds = Flair1Dataset(folder_path, split=\"toy_tr\")\n",
    "toy_dl = torch.utils.data.DataLoader(toy_ds, batch_size=batch_size, shuffle=True)\n",
    "img, msk = next(iter(toy_dl))\n",
    "plot_image_mask(img[0], msk[0], colors, dict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Flair1Dataset(folder_path, split=\"train\")\n",
    "val_ds = Flair1Dataset(folder_path, split=\"valid\")\n",
    "test_ds = Flair1Dataset(folder_path, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the functions for training, validation and test, with plots of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training function (trains for one epoch)\n",
    "def train(model, train_loader, loss_fn, optimizer):\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # main training loop\n",
    "    pbar = tqdm(total=len(train_loader), desc=\"[Train]\")\n",
    "    training_loss = 0\n",
    "    pixel_acc = PixelwiseMetrics(train_loader.dataset.n_classes)\n",
    "    conf_mat = ConfMatrix(train_loader.dataset.n_classes)\n",
    "    for batch_idx, (image, target) in enumerate(train_loader):\n",
    "        #print(image.shape)\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # move data to gpu if model is on gpu\n",
    "        if use_gpu:\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "\n",
    "        # forward pass\n",
    "        prediction = model(image)\n",
    "        #print(target.shape)\n",
    "        training_loss += loss_fn(prediction, target).data.item()\n",
    "        loss = loss_fn(prediction, target)\n",
    "        pixel_acc.add_batch(target, prediction.max(1)[1])\n",
    "        conf_mat.add_batch(target, prediction.max(1)[1])\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progressbar\n",
    "\n",
    "        '''    pbar.set_description(\"[Train] Loss: {:.4f}\".format(\n",
    "                                round(training_loss.item(), 4)))\n",
    "        pbar.set_description(\"[Train] Pixel-wise accuracy: {:.2f}%\".format(\n",
    "                                round(pixel_acc.get_average_accuracy() * 100, 2)))\n",
    "        pbar.set_description(\"[Train] mIoU: {:.2f}%\".format(\n",
    "                                round(conf_mat.get_mIoU()) * 100, 2))'''\n",
    "        pbar.update()\n",
    "\n",
    "    # close progressbar and flush to disk\n",
    "    pbar.close()\n",
    "    training_loss /= len(train_loader)\n",
    "    return model, training_loss, pixel_acc.get_average_accuracy(), pixel_acc.get_classwise_accuracy(), conf_mat.get_mIoU()\n",
    "\n",
    "# main validation function (validates current model)\n",
    "def val(model, val_loader, loss_fn, optimizer):\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # main validation loop\n",
    "    pbar = tqdm(total=len(val_loader), desc=\"[Val]\")\n",
    "    loss = 0\n",
    "    val_pixel_acc = PixelwiseMetrics(val_loader.dataset.n_classes)\n",
    "    val_conf_mat = ConfMatrix(val_loader.dataset.n_classes)\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(val_loader):\n",
    "\n",
    "        # move data to gpu if model is on gpu\n",
    "        if use_gpu:\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "\n",
    "        # forward pass\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image)\n",
    "        loss += loss_fn(prediction, target).cpu().item()\n",
    "\n",
    "        # calculate error metrics\n",
    "        val_conf_mat.add_batch(target, prediction.max(1)[1])\n",
    "        val_pixel_acc.add_batch(target, prediction.max(1)[1])\n",
    "\n",
    "        # update progressbar\n",
    "        pbar.update()\n",
    "\n",
    "    '''    # close progressbar\n",
    "    pbar.set_description(\"[Val] Pixel-wise accuracy: {:.2f}%\".format(\n",
    "                            round(val_pixel_acc.get_average_accuracy() * 100, 2)))'''\n",
    "    pbar.close()\n",
    "\n",
    "    model.train()\n",
    "    return loss / len(val_loader), val_pixel_acc.get_average_accuracy(), val_pixel_acc.get_classwise_accuracy(), val_conf_mat.get_mIoU()\n",
    "\n",
    "def export_model(model, optimizer=None, name=None, step=None):\n",
    "\n",
    "    # set output filename\n",
    "    if name is not None:\n",
    "        out_file = name\n",
    "    else:\n",
    "        out_file = \"checkpoint\"\n",
    "        if step is not None:\n",
    "            out_file += \"_step_\" + str(step)\n",
    "    #out_file = os.path.join(self.args.checkpoint_dir, out_file + \".pth\")\n",
    "\n",
    "    # save model\n",
    "    data = {\"model_state_dict\": model.state_dict()}\n",
    "    if step is not None:\n",
    "        data[\"step\"] = step\n",
    "    if optimizer is not None:\n",
    "\n",
    "        data[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    torch.save(data, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm for a tiny subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_tr_ds = Flair1Dataset(folder_path, split=\"toy_tr\")\n",
    "toy_tr_dl = torch.utils.data.DataLoader(toy_tr_ds, batch_size=batch_size, shuffle=True)\n",
    "toy_vl_ds = Flair1Dataset(folder_path, split=\"toy_vl\")\n",
    "toy_vl_dl = torch.utils.data.DataLoader(toy_vl_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_classes = toy_tr_ds.n_classes\n",
    "n_inputs = toy_vl_ds.n_inputs\n",
    "model = UNet(n_classes=n_classes, n_channels=n_inputs) #pixel value from 1 to 18\n",
    "train_pixelAcc = PixelwiseMetrics(n_classes)\n",
    "#model = SimpleUNet(3, 18)\n",
    "# model = model.float()\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=255, reduction='mean')\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "#train_loss, val_loss, train_pixel_acc, val_pixel_acc = train(model, toy_tr_ds, toy_vl_ds, loss_fn, optimizer, epochs=5)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    # run training for one epoch\n",
    "    model, tr_loss, tr_mean_acc, tr_class_acc, mIoU = train(model, toy_tr_dl, loss_fn, optimizer)\n",
    "    train_losses.append(tr_loss)\n",
    "    # run validation\n",
    "    val_loss, val_mean_acc, val_class_acc, mIoU = val(model, toy_vl_dl, loss_fn, optimizer)\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"Training loss: \", tr_loss)\n",
    "    print(\"Training mean accuracy: \", tr_mean_acc)\n",
    "    print(\"Training classwise accuracy: \", tr_class_acc)\n",
    "    print(\"Training mIoU: \", mIoU)\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "    print(\"Validation mean accuracy: \", val_mean_acc)\n",
    "    print(\"Validation classwise accuracy: \", val_class_acc)\n",
    "    print(\"Validation mIoU: \", mIoU)    \n",
    "    #trainer.export_model(model, args.checkpoint_dir, name=\"final\")\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation with the trained model on vl_dl\n",
    "val_loss, val_mean_acc, val_class_acc, mIoU = val(model, toy_vl_dl, loss_fn, optimizer)\n",
    "print(\"-----------------------\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation mean accuracy: \", val_mean_acc)\n",
    "print(\"Validation classwise accuracy: \", val_class_acc)\n",
    "print(\"Validation mIoU: \", mIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print validation accuracy class by class\n",
    "for i in range(len(val_class_acc)):\n",
    "    print(i+1, dict_classes[i+1], \" : \", val_class_acc[\"pixelclass_\"+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_per_per_class() to get the percentage of each class in the dataset\n",
    "toy_tr_ds = Flair1Dataset(folder_path, split=\"toy_tr\")\n",
    "per_class = toy_tr_ds.get_per_per_class()\n",
    "plot_per_classes(per_class, dict_classes, colors, title = 'toy training dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
